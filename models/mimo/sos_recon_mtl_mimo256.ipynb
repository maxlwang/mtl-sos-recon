{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81zubI5TkEUE"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NajEdsGoj62E"
   },
   "source": [
    "# Install Depedencies and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGMszuHzm_pd"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from PIL import ImageOps\n",
    "from PIL import Image as im\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import sys\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybspf_z7ip2Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download and unzip training and test data\n",
    "url = ''\n",
    "output = ''\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "with zipfile.ZipFile(\"\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuYcFRFZiTCR"
   },
   "source": [
    "# Prepare paths of input images and target segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUYjO516iTCh",
    "outputId": "eac43c61-f8d2-4f75-aaa2-ec1136e04701",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_dir = \"\"\n",
    "uimg_dir = \"\"\n",
    "sos_dir = \"\"\n",
    "img_dir = \"\"\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "uimg_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(uimg_dir, fname)\n",
    "        for fname in os.listdir(uimg_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "sos_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(sos_dir, fname)\n",
    "        for fname in os.listdir(sos_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "bm_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(img_dir, fname)\n",
    "        for fname in os.listdir(img_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(input_img_paths))\n",
    "\n",
    "for input_path, uimg_path, sos_path, img_path in zip(input_img_paths[:10], uimg_img_paths[:10], sos_img_paths[:10], bm_img_paths[:10]):\n",
    "    print(input_path, \"|\", uimg_path, \"|\", sos_path, \"|\", img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dir = \"\"\n",
    "test_sos_dir = \"\"\n",
    "test_img_dir = \"\"\n",
    "test_uimg_dir = \"\"\n",
    "\n",
    "test_input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_input_dir, fname)\n",
    "        for fname in os.listdir(test_input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "test_uimg_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_uimg_dir, fname)\n",
    "        for fname in os.listdir(test_uimg_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "test_sos_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_sos_dir, fname)\n",
    "        for fname in os.listdir(test_sos_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "test_bm_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_img_dir, fname)\n",
    "        for fname in os.listdir(test_img_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(test_input_img_paths))\n",
    "\n",
    "for input_path, uimg_path, sos_path, img_path in zip(test_input_img_paths[:10],test_uimg_img_paths[:10], test_sos_img_paths[:10], test_bm_img_paths[:10]):\n",
    "    print(input_path, \"|\", uimg_path, \"|\", sos_path, \"|\", img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_dir = \"\"\n",
    "val_sos_dir = \"\"\n",
    "val_img_dir = \"\"\n",
    "val_uimg_dir = \"\"\n",
    "\n",
    "val_input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(val_input_dir, fname)\n",
    "        for fname in os.listdir(val_input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "val_uimg_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(val_uimg_dir, fname)\n",
    "        for fname in os.listdir(val_uimg_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")    \n",
    "val_sos_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(val_sos_dir, fname)\n",
    "        for fname in os.listdir(val_sos_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "val_bm_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(val_img_dir, fname)\n",
    "        for fname in os.listdir(val_img_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(val_input_img_paths))\n",
    "\n",
    "for input_path, uimg_path, sos_path, img_path in zip(val_input_img_paths[:10],val_uimg_img_paths[:10], val_sos_img_paths[:10], val_bm_img_paths[:10]):\n",
    "    print(input_path, \"|\", uimg_path, \"|\", sos_path, \"|\", img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQmSbPYZiTCi"
   },
   "source": [
    "# What does one input image and corresponding segmentation mask look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoxtaK85iTEi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display input image #7\n",
    "ascan = ImageOps.autocontrast(load_img(input_img_paths[7]))\n",
    "display(ascan)\n",
    "\n",
    "uimg = ImageOps.autocontrast(load_img(uimg_img_paths[7]))\n",
    "display(uimg)\n",
    "\n",
    "# Display auto-contrast version of corresponding SoS Map \n",
    "sos = ImageOps.autocontrast(load_img(sos_img_paths[7]))\n",
    "display(sos)\n",
    "\n",
    "# Display auto-contrast version of corresponding reconstructed Root image\n",
    "img = ImageOps.autocontrast(load_img(bm_img_paths[7]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sWLRqEoiTFA"
   },
   "source": [
    "# Prepare `Sequence` class to load & vectorize batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPE55i6ziTFB"
   },
   "outputs": [],
   "source": [
    "img_size = (256, 256)\n",
    "batch_size = 12\n",
    "\n",
    "class Ascans(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, input_uimg_paths, sos_img_paths, bm_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.input_uimg_paths = input_uimg_paths\n",
    "        self.sos_img_paths = sos_img_paths\n",
    "        self.bm_img_paths = bm_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sos_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_input_uimg_paths = self.input_uimg_paths[i : i + self.batch_size]\n",
    "        batch_sos_img_paths = self.sos_img_paths[i : i + self.batch_size]\n",
    "        batch_bm_img_paths = self.bm_img_paths[i : i + self.batch_size]\n",
    "        x1 = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            x1[j] = np.expand_dims(img, 2)\n",
    "        x2 = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_input_uimg_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x2[j] = img\n",
    "        y1 = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        y2 = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_sos_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y1[j] = np.expand_dims(img, 2)    # converts array to (img,1)\n",
    "        for j, path in enumerate(batch_bm_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y2[j] = np.expand_dims(img, 2)    # converts array to (img,1)\n",
    "        return [x1, x2], [y1, y2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAaaXC2liTFG"
   },
   "source": [
    "# Multi-task U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJsIiwupiTFJ",
    "outputId": "aa20952e-7755-4856-97b5-645d353bf64b"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "keras.backend.clear_session()\n",
    "model = unet_mtl_mimo_deeper(img_size, 1, 3)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEw8NwB5iTFO"
   },
   "source": [
    "# Set aside a validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvaWjIWSiTFT"
   },
   "outputs": [],
   "source": [
    "train_input_img_paths = input_img_paths\n",
    "train_input_uimg_paths = uimg_img_paths\n",
    "train_sos_img_paths = sos_img_paths\n",
    "train_bm_img_paths = bm_img_paths\n",
    "val_input_img_paths = val_input_img_paths\n",
    "val_input_uimg_paths = val_uimg_img_paths\n",
    "val_sos_img_paths = val_sos_img_paths\n",
    "val_bm_img_paths = val_bm_img_paths\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = Ascans(batch_size, img_size, train_input_img_paths, train_input_uimg_paths, train_sos_img_paths, train_bm_img_paths)\n",
    "val_gen = Ascans(batch_size, img_size, val_input_img_paths, val_input_uimg_paths, val_sos_img_paths, val_bm_img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5j42YGFiTFU"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KIRvcImtiTFc"
   },
   "outputs": [],
   "source": [
    "# Configure the model for training.\n",
    "plot_progress = PlotProgress(entity='loss')\n",
    "optimizer = tfa.optimizers.AdamW(weight_decay = 0, learning_rate = 5e-4)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss={'sos_output': 'mse', 'img_output': 'mse'}, \n",
    "              loss_weights={'sos_output': 0.5, 'img_output': 0.5})\n",
    "\n",
    "#model.load_weights('sos_recon.h5')\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"sos_recon_val.h5\", monitor=\"val_loss\", save_best_only=True),\n",
    "    keras.callbacks.ModelCheckpoint(\"sos_recon.h5\", monitor=\"loss\", save_best_only=True),\n",
    "    plot_progress\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KIRvcImtiTFc"
   },
   "outputs": [],
   "source": [
    "# Train the model, doing validation at the end of each epoch.\n",
    "epochs = 100\n",
    "model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQw84aKWiTFc"
   },
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wwmc4b6jiTFe"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for all images in the validation set\n",
    "model.load_weights('sos_recon_val.h5')\n",
    "\n",
    "val_gen = Ascans(10, img_size, val_input_img_paths, val_input_uimg_paths, val_sos_img_paths, val_bm_img_paths)\n",
    "val_preds = model.predict(val_gen)\n",
    "val_results = model.evaluate(val_gen)\n",
    "\n",
    "train_gen = Ascans(10, img_size, train_input_img_paths[0:500], train_input_uimg_paths[0:500], train_sos_img_paths[0:500], train_bm_img_paths[0:500])\n",
    "train_preds = model.predict(train_gen)\n",
    "train_results = model.evaluate(train_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = Ascans(10, img_size, test_input_img_paths, test_uimg_img_paths, test_sos_img_paths, test_bm_img_paths)\n",
    "test_preds = model.predict(test_gen)\n",
    "test_results = model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_preds[0].shape)\n",
    "train_truth = np.zeros((4,)+ np.squeeze(train_preds[0]).shape)\n",
    "val_truth = np.zeros((4,)+ np.squeeze(train_preds[0]).shape)\n",
    "test_truth = np.zeros((4,)+ np.squeeze(train_preds[0]).shape)\n",
    "\n",
    "for i in range(500):\n",
    "    train_truth[0,i] = np.asarray(load_img(train_input_img_paths[i], color_mode = 'grayscale'))\n",
    "    train_truth[1,i] = np.asarray(load_img(train_input_uimg_paths[i], color_mode = 'grayscale'))\n",
    "    train_truth[2,i] = np.asarray(load_img(train_sos_img_paths[i], color_mode = 'grayscale'))\n",
    "    train_truth[3,i] = np.asarray(load_img(train_bm_img_paths[i], color_mode = 'grayscale'))\n",
    "    \n",
    "    val_truth[0,i] = np.asarray(load_img(val_input_img_paths[i], color_mode = 'grayscale'))\n",
    "    val_truth[1,i] = np.asarray(load_img(val_input_uimg_paths[i], color_mode = 'grayscale'))\n",
    "    val_truth[2,i] = np.asarray(load_img(val_sos_img_paths[i], color_mode = 'grayscale'))\n",
    "    val_truth[3,i] = np.asarray(load_img(val_bm_img_paths[i], color_mode = 'grayscale'))\n",
    "    \n",
    "    test_truth[0,i] = np.asarray(load_img(test_input_img_paths[i], color_mode = 'grayscale'))\n",
    "    test_truth[1,i] = np.asarray(load_img(test_uimg_img_paths[i], color_mode = 'grayscale'))\n",
    "    test_truth[2,i] = np.asarray(load_img(test_sos_img_paths[i], color_mode = 'grayscale'))\n",
    "    test_truth[3,i] = np.asarray(load_img(test_bm_img_paths[i], color_mode = 'grayscale'))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import *\n",
    "\n",
    "save_path = ''\n",
    "save_var = {\"val_preds\":val_preds, \"train_preds\":train_preds, \n",
    "            \"test_preds\": test_preds, \"val_results\": val_results, \"train_results\": train_results, \n",
    "            \"test_results\": test_results, \"batch_size\": batch_size, \"train_truth\": train_truth, \n",
    "            \"val_truth\": val_truth, \"test_truth\": test_truth, \"train_input_img_paths\": train_input_img_paths, \n",
    "            \"train_input_uimg_paths\": train_input_uimg_paths, \"val_input_img_paths\": val_input_img_paths, \n",
    "            \"test_input_img_paths\": test_uimg_img_paths}\n",
    "save_var[\"plot_progress\"] = plot_progress.logs\n",
    "savemat(save_path, save_var)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sos_recon_mtl_ascan_input.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
